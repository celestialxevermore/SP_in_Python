{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataloaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/993102397.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrawvideo_util\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRawVideoExtractor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dataloaders'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pickle\n",
    "from dataloaders.rawvideo_util import RawVideoExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSVD_DataLoader(Dataset):\n",
    "    \"\"\"MSVD dataset loader.\"\"\"\n",
    "    def __init__(self, subset, data_path,features_path,tokenizer,max_words=30,feature_framerate=1.0,max_frames=100,image_resolution=224,frame_order=0,slice_framepos=0,):\n",
    "        self.data_path = data_path\n",
    "        self.features_path = features_path,\n",
    "        self.feature_framerate = feature_framerate \n",
    "        self.max_words = max_words \n",
    "        self.max_frames = max_frames \n",
    "        self.tokenizer = tokenizer \n",
    "\n",
    "        # 0 : 일반적인 순서 1 : 역순서 2 무작위 순서 \n",
    "        self.frame_order = frame_order \n",
    "        assert self.frame_order in [0,1,2]\n",
    "\n",
    "        # 0 : cut from head freams; 1 : cut from tail frames, 2 : extract frames uniformly.\n",
    "        self.slice_framepos = slice_framepos \n",
    "        assert self.slice_framepos in[0,1,2]\n",
    "\n",
    "        self.subset = subset \n",
    "        assert self.subset in [\"train\",\"val\",\"test\"]\n",
    "\n",
    "        #오 이게 좀 중요해보이는구나.\n",
    "        video_id_path_dict={}\n",
    "\n",
    "        video_id_path_dict[\"train\"]= os.path.join(self.data_path,\"train_list.txt\")\n",
    "        video_id_path_dict[\"val\"] = os.path.join(self.data_path,\"val_list.txt\")\n",
    "        video_id_path_dict[\"test\"] = os.path.join(self.data_path,\"test_list.txt\")\n",
    "\n",
    "        caption_file = os.path.join(self.data_path,\"raw-captions.pkl\")\n",
    "\n",
    "        #self.subset은 train val test 중 하나임\n",
    "        #txt파일을 하나씩 읽어와서 한줄로 나열한다. 좌우 공백을 전부 없앤다. \n",
    "        with open(video_id_path_dict[self.subset],'r') as fp:\n",
    "            video_ids=[itm.strip() for itm in fp.readlines()]\n",
    "            print(\"current video_ids \",video_ids)\n",
    "\n",
    "        with open(caption_file,'rb') as f:\n",
    "            captions = pickle.load(f)\n",
    "            print(\"current captions \",captions)\n",
    "\n",
    "        video_dict={}\n",
    "        #features_path 는 모든 비디오의 내용이 들어가 있음. \n",
    "        with open(self.features_path,'r') as features:\n",
    "            features = os.path.join(self.features_path,\"all_videos\")\n",
    "        \n",
    "        print(\"features!! :\",features)\n",
    "\n",
    "        for root,dub_dir,video_files in os.walk(self.features_path):\n",
    "            for video_file in video_files:\n",
    "                video_id_ = \".\".join(video_file.split(\".\")[:-1])\n",
    "                if video_id_ not in video_ids:\n",
    "                    continue #걍 안전코딩 \n",
    "            print(\"done!\",video_id_)\n",
    "            file_path_ = os.path.join(root,video_file)\n",
    "            video_dict[video_id_]=file_path_\n",
    "        self.video_dict = video_dict \n",
    "        print('done video_dict :',self.video_dict)\n",
    "\n",
    "        self.sample_len=0\n",
    "        self.sentences_dict={}\n",
    "        self.cut_off_points=[]\n",
    "        for video_id in video_ids:\n",
    "            assert video_id in captions \n",
    "            for cap in captions[video_id]:\n",
    "                cap_txt = \" \".join(cap)\n",
    "                self.sentences_dict[len(self.sentences_dict)]=(video_id,cap_txt)\n",
    "            self.cut_off_points.append(len(self.sentences_dict))\n",
    "\n",
    "        #self.sentences_dict는 각 video_id에 대하여 모든 caption을 일렬로 이어붙인 텍스트를 value로 갖는 딕셔너리\n",
    "        \n",
    "        self.multi_sentence_per_video = True # !!! important tag for eval\n",
    "        \n",
    "        if self.subset == \"val\" or self.subset == \"test\":\n",
    "            self.sentence_num = len(self.sentences_dict)\n",
    "            self.video_num = len(video_ids)\n",
    "\n",
    "            assert len(self.cut_off_points) == self.video_num \n",
    "            print(\"For {}, sentence number : {}\".format(self.subset,self.sentence_num))\n",
    "            print(\"For {}, video number : {}\".format(self.subset,self.video_num))\n",
    "        \n",
    "        print(\"Video number : {}\".format(len(self.video_dict)))\n",
    "        print(\"Total Paire : {}\".format(len(self.sentences_dict)))\n",
    "\n",
    "        self.sample_len = len(self.sentences_dict)\n",
    "\n",
    "        #RawVideoExtractor는 말그대로 정제를 하는 역할을 한다.\n",
    "        self.rawVideoExtractor = RawVideoExtractor(framerate=feature_framerate,size=image_resolution)\n",
    "        self.SPECIAL_TOKEN = {\"CLS_TOKEN\": \"<|startoftext|>\", \"SEP_TOKEN\": \"<|endoftext|>\",\n",
    "                              \"MASK_TOKEN\": \"[MASK]\", \"UNK_TOKEN\": \"[UNK]\", \"PAD_TOKEN\": \"[PAD]\"}\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.sample_len \n",
    "    \n",
    "    #BERT에 들어갈 수 있도록 조작함.\n",
    "    def _get_text(self,video_id,caption):\n",
    "        k=1 \n",
    "        choice_video_ids = [video_id]\n",
    "        #전체 길이만큼 쭉 zeros를 만든다.\n",
    "        pairs_text = np.zeros((k,self.max_words), dtype=np.long)\n",
    "        pairs_mask = np.zeros((k,self.max_words),dtype=np.long)\n",
    "        pairs_segment = np.zeros((k,self.max_words),dtype=np.long)\n",
    "\n",
    "        for i, video_id in enumerate(choice_video_ids):\n",
    "            #토크나이즈를 하고난 뒤\n",
    "            words = self.tokenizer.tokenize(caption)\n",
    "            #CLS 토큰을 앞에다가 붙인다.\n",
    "            words = [self.SPECIAL_TOKEN[\"CLS_TOKEN\"]] + words\n",
    "\n",
    "            total_length_with_CLS = self.max_words -1 \n",
    "            if len(words) > total_length_with_CLS:\n",
    "                words = words[:total_length_with_CLS]\n",
    "            #그런 다음 뒤에 SEP 토큰을 붙인다. 문장 사이의 구분을 위해서.\n",
    "            words = words + [self.SPECIAL_TOKEN[\"SEP_TOKEN\"]] \n",
    "\n",
    "            input_ids = self.tokenizer.convert_tokens_to_ids(words)\n",
    "            input_mask = [1] * len(input_ids)\n",
    "            segment_ids = [0] * len(input_ids)\n",
    "            while len(input_ids) < self.max_words:\n",
    "                input_ids.append(0)\n",
    "                input_mask.append(0)\n",
    "                segment_ids.append(0)\n",
    "            \n",
    "            assert len(input_ids) == self.max_words\n",
    "            assert len(input_mask) == self.max_words\n",
    "            assert len(segment_ids) == self.max_words \n",
    "\n",
    "            pairs_text[i]=np.array(input_ids)\n",
    "            pairs_mask[i] = np.array(input_mask)\n",
    "            pairs_segment[i] = np.array(segment_ids)\n",
    "        \n",
    "        return pairs_text, pairs_mask, pairs_segment, choice_video_ids \n",
    "\n",
    "    \n",
    "    def _get_rawvideo(self,choice_video_ids):\n",
    "        video_mask = np.zeros((len(choice_video_ids),self.max_frames),dtype=np.long)\n",
    "        print(\"before video_mask :\",video_mask)\n",
    "        max_video_length = [0] * len(choice_video_ids)\n",
    "\n",
    "        # Pair x L x T x 3 x H x W \n",
    "        video = np.zeros((len(choice_video_ids),self.max_frames,1,3,self.rawVideoExtractor.size,self.rawVideoExtractor.size),dtype = np.float)\n",
    "        print(\"raw video shape :\",video.shape)\n",
    "        print(\"len(choice_video_ids) :\",len(choice_video_ids))\n",
    "        print(\"self.max_frames :\",self.max_frames)\n",
    "\n",
    "        for i,video_id in enumerate(choice_video_ids):\n",
    "            #video_dict는 video_id가 key이고, 해당 video의 경로가 value인 객체입니다.\n",
    "            video_path = self.video_dict[video_id]\n",
    "\n",
    "            #raw_video_data는 정제가 되어서 tensor로 바뀌어버린 것임 video -> tensor\n",
    "            raw_video_data = self.rawVideoExtractor.get_video_data(video_path)\n",
    "            print(\"raw_video_data \",raw_video_data)\n",
    "            print(\"raw_video_data shape :\",raw_video_data.shape)\n",
    "            \"\"\"\n",
    "                def get_video_data(self, video_path, start_time=None, end_time=None):\n",
    "                    image_input = self.video_to_tensor(video_path, self.transform, sample_fp=self.framerate, start_time=start_time, end_time=end_time)\n",
    "                    return image_input\n",
    "            \"\"\"\n",
    "            \n",
    "\n",
    "\n",
    "            raw_video_data = raw_video_data['video']\n",
    "\n",
    "            if len(raw_video_data.shape) > 3:\n",
    "                raw_video_data_clip = raw_video_data \n",
    "\n",
    "            # L x T x 3 x H x W \n",
    "            # T : max_frames \n",
    "            # if self.max_frames < raw_video_slice.shape[0]:\n",
    "            # 조건문으로 인해서 L이 max_frame이 됩니다.\n",
    "                raw_video_slice = self.rawVideoExtractor.process_raw_data(raw_video_data_clip)\n",
    "                tensor_size = raw_video_data_clip.size()\n",
    "                tensor = raw_video_data_clip.view(-1,1,tensor_size[-3],tensor_size[-2],tensor_size[-1])\n",
    "                raw_video_slice_ = tensor \n",
    "                \n",
    "                if self.max_frames < raw_video_slice.shape[0]:\n",
    "                    if self.slice_framepos == 0:\n",
    "                        video_slice = raw_video_slice[:self.max_frames, ...]\n",
    "                    elif self.slice_framepos == 1:\n",
    "                        video_slice = raw_video_slice[-self.max_frames:, ...]\n",
    "                    else:\n",
    "                        sample_indx = np.linspace(0, raw_video_slice.shape[0] - 1, num=self.max_frames, dtype=int)\n",
    "                        video_slice = raw_video_slice[sample_indx, ...]\n",
    "                else:\n",
    "                    video_slice = raw_video_slice\n",
    "\n",
    "                video_slice = self.rawVideoExtractor.process_frame_order(video_slice, frame_order=self.frame_order)\n",
    "\n",
    "                slice_len = video_slice.shape[0]\n",
    "                max_video_length[i] = max_video_length[i] if max_video_length[i] > slice_len else slice_len\n",
    "                if slice_len < 1:\n",
    "                    pass\n",
    "                else:\n",
    "                    video[i][:slice_len, ...] = video_slice\n",
    "            else:\n",
    "                print(\"video path: {} error. video id: {}\".format(video_path, video_id))\n",
    "\n",
    "        for i, v_length in enumerate(max_video_length):\n",
    "            video_mask[i][:v_length] = [1] * v_length\n",
    "\n",
    "        return video, video_mask\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        #키와 밸류를 각각 가져옵니다.\n",
    "        video_id, caption = self.sentences_dict[idx]\n",
    "        print(\"extracted video id from sentences_dict :\",video_id)\n",
    "        print(\"extracted caption in one line from sentences_dict :\",caption)\n",
    "\n",
    "        #각각 get_text와 get_rawvideo를 통해 산출\n",
    "        pairs_text,pairs_mask,pairs_segment,choice_video_ids = self._get_text(video_id,caption)\n",
    "        video,video_mask = self._get_rawvideo(choice_video_ids)\n",
    "        \n",
    "        return pairs_text,pairs_mask,pairs_segment, video,video_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_raw_data(self, raw_video_data):\n",
    "    tensor_size = raw_video_data.size()\n",
    "    #뭐야 그대로 반환하는데? \n",
    "    tensor = raw_video_data.view(-1,1,tensor_size[-3],tensor_size[-2],tensor_size[-1])\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dataloaders'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/4107232640.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader_msrvtt_retrieval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMSRVTT_DataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader_msrvtt_retrieval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMSRVTT_TrainDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader_msvd_retrieval\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMSVD_DataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dataloaders'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from dataloaders.dataloader_msrvtt_retrieval import MSRVTT_DataLoader\n",
    "from dataloaders.dataloader_msrvtt_retrieval import MSRVTT_TrainDataLoader\n",
    "from dataloaders.dataloader_msvd_retrieval import MSVD_DataLoader\n",
    "from dataloaders.dataloader_lsmdc_retrieval import LSMDC_DataLoader\n",
    "from dataloaders.dataloader_activitynet_retrieval import ActivityNet_DataLoader\n",
    "from dataloaders.dataloader_didemo_retrieval import DiDeMo_DataLoader\n",
    "from modules.tokenization_clip import SimpleTokenizer as ClipTokenizer\n",
    "from dataloaders.data_dataloaders import DATALOADER_DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easydict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/2321160463.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0measydict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mDATA_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/home/key2317/CLIP4Clip/msvd_data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mFEATURES_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"/home/key2317/CLIP4Clip/msvd_data/MSVD_Videos\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m args = easydict.EasyDict({\n\u001b[0;32m      5\u001b[0m     \u001b[1;34m\"data_path\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'easydict'"
     ]
    }
   ],
   "source": [
    "import easydict \n",
    "DATA_PATH = \"/home/key2317/CLIP4Clip/msvd_data\"\n",
    "FEATURES_PATH = \"/home/key2317/CLIP4Clip/msvd_data/MSVD_Videos\"\n",
    "args = easydict.EasyDict({\n",
    "    \"data_path\":DATA_PATH,\n",
    "    \"features_path\":FEATURES_PATH,\n",
    "    \"max_words\":30,\n",
    "    \"feature_framerate\":1,\n",
    "    \"max_frames\":100,\n",
    "    \"image_resolution\":224,\n",
    "    \"frame_order\":0,\n",
    "    \"slice_framepos\":0,\n",
    "    \"train_frame_order\":0, #default 0, choice = [0,1,2]\n",
    "    \"batch_size\":256,\n",
    "    \"n_gpu\":torch.cuda.device_count(), #default :1\n",
    "    \"num_thread_reader\":1,\n",
    "    \"datatype\":\"msvd\",\n",
    "    \"eval_frame_order\":0, #choices = [0, 1, 2]\n",
    "    \"batch_size_val\":3500,\n",
    "})\n",
    "\n",
    "print(args.__dict__)\n",
    "tokenizer = ClipTokenizer()\n",
    "#train_dataloader, train_length, train_sampler = DATALOADER_DICT[args.datatype][\"train\"](args, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_msvd_train(args,tokenizer):\n",
    "    msvd_dataset=MSVD_DataLoader(\n",
    "        subset = \"train\",\n",
    "        data_path = args.data_path,\n",
    "        features_path = args.features_path,\n",
    "        max_words = args.max_words,\n",
    "        feature_framerate=args.feature_framerate,\n",
    "        tokenizer = tokenizer,\n",
    "        max_frames=args.max_frames,\n",
    "        frame_order = args.train_frame_order, \n",
    "        slice_framepos = args.slice_framepos\n",
    "    )\n",
    "\n",
    "    #train_sampler = torch.utils.data.distributed.DistributedSampler(msvd_dataset)\n",
    "    train_sampler = 0\n",
    "    dataloader = DataLoader(\n",
    "        msvd_dataset,\n",
    "        batch_size = args.batch_size // args.n_gpu, \n",
    "        num_workers = args.num_thread_reader,\n",
    "        pin_memory=False, \n",
    "        shuffle = (train_sampler is None), \n",
    "        sampler = train_sampler, \n",
    "        drop_last=True,\n",
    "\n",
    "        \n",
    "    )\n",
    "\n",
    "    return msvd_dataset, dataloader, len(msvd_dataset),train_sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_msvd_test(args, tokenizer, subset=\"test\"):\n",
    "    msvd_testset = MSVD_DataLoader(\n",
    "        subset=subset,\n",
    "        data_path=args.data_path,\n",
    "        features_path=args.features_path,\n",
    "        max_words=args.max_words,\n",
    "        feature_framerate=args.feature_framerate,\n",
    "        tokenizer=tokenizer,\n",
    "        max_frames=args.max_frames,\n",
    "        frame_order=args.eval_frame_order,\n",
    "        slice_framepos=args.slice_framepos,\n",
    "    )\n",
    "    dataloader_msvd = DataLoader(\n",
    "        msvd_testset,\n",
    "        batch_size=args.batch_size_val,\n",
    "        num_workers=args.num_thread_reader,\n",
    "        shuffle=False,\n",
    "        drop_last=False,\n",
    "    )\n",
    "    return msvd_testset, dataloader_msvd, len(msvd_testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/1412139290.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmsvd_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen_of_msvdtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_sampler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader_msvd_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmsvd_testset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen_of_msvdtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader_msvd_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "msvd_dataset,train_dataloader,len_of_msvdtrain,train_sampler = dataloader_msvd_train(args,tokenizer)\n",
    "msvd_testset, test_dataloader, len_of_msvdtest = dataloader_msvd_test(args,tokenizer,subset=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/2305427253.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DATA PATH :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"FEATURE PATH :\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFEATURES_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"DATA PATH :\",DATA_PATH)\n",
    "print(\"FEATURE PATH :\",FEATURES_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DATA_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/553048378.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvideo_id_path_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvideo_id_path_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"train_list.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mvideo_id_path_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"val_list.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mvideo_id_path_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test_list.txt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcaption_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDATA_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"raw-captions.pkl\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'DATA_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "video_id_path_dict = {}\n",
    "video_id_path_dict[\"train\"] = os.path.join(DATA_PATH, \"train_list.txt\")\n",
    "video_id_path_dict[\"val\"] = os.path.join(DATA_PATH, \"val_list.txt\")\n",
    "video_id_path_dict[\"test\"] = os.path.join(DATA_PATH, \"test_list.txt\")\n",
    "caption_file = os.path.join(DATA_PATH, \"raw-captions.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'caption_file' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/1809119517.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcaption_file\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mcaptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_id_path_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mvideo_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mitm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitm\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'caption_file' is not defined"
     ]
    }
   ],
   "source": [
    "with open(caption_file,'rb') as f:\n",
    "    captions = pickle.load(f)\n",
    "\n",
    "with open(video_id_path_dict[\"train\"], 'r') as fp:\n",
    "    video_ids = [itm.strip() for itm in fp.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/3463947767.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mvideo_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdub_dir\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvideo_files\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mvideo_file\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvideo_files\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mvideo_id_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\".\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mvideo_id_\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvideo_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "video_dict = {} \n",
    "for root, dub_dir,video_files in os.walk(args.features_path):\n",
    "    for video_file in video_files:\n",
    "        video_id_ = \".\".join(video_file.split(\".\")[:-1])\n",
    "        if video_id_ not in video_ids:\n",
    "            continue\n",
    "        file_path_ = os.path.join(root,video_file)\n",
    "        video_dict[video_id_] = file_path_ \n",
    "\n",
    "#print(video_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'video_ids' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/185676799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentences_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mcut_off_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mvideo_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvideo_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mvideo_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcap\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcaptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'video_ids' is not defined"
     ]
    }
   ],
   "source": [
    "sentences_dict = {} \n",
    "cut_off_points=[] \n",
    "for video_id in video_ids:\n",
    "    assert video_id in captions \n",
    "    for cap in captions[video_id]:\n",
    "        cap_txt = \" \".join(cap)\n",
    "        sentences_dict[len(sentences_dict)] = (video_id,cap_txt)\n",
    "    cut_off_points.append(len(sentences_dict))\n",
    "#print(sentences_dict)\n",
    "#print(cut_off_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences_dict) #total paire에 해당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_9180/2124376157.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mvideo_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaption\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentences_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mpairs_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpairs_segment\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchoice_video_ids\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mmsvd_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvideo_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcaption\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpairs_text\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 1"
     ]
    }
   ],
   "source": [
    "idx = 1 \n",
    "video_id,caption = sentences_dict[idx]\n",
    "pairs_text, pairs_mask, pairs_segment, choice_video_ids  = msvd_dataset._get_text(video_id,caption)\n",
    "\n",
    "print(pairs_text.shape)\n",
    "print(pairs_mask.shape)\n",
    "print(pairs_segment.shape)\n",
    "print(choice_video_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(sentences_dict)):\n",
    "    video_id,caption = sentences_dict[idx]\n",
    "    pairs_text, pairs_mask, pairs_segment, choice_video_ids  = msvd_dataset._get_text(video_id,caption)\n",
    "    print(\"pairs_text shape : {} pairs_mask shape : {} pair_segment shape : {} choice_video_ids : {}\".format(pairs_text.shape,pairs_mask.shape,pairs_segment.shape,choice_video_ids))\n",
    "    video, video_mask = msvd_dataset._get_rawvideo(choice_video_ids)\n",
    "    print(\"video shape : {} video_mask shape: {}\".format(video.shape,video_mask.shape))\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c45c269bc2f1467f51b0d7ce18bdfa2841a09c768d41ed69b0f11077738bf91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
