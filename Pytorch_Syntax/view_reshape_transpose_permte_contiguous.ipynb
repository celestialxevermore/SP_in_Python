{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View reshape, transpose, permute 함수의 차이와, contiguous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 12])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,4)\n",
    "y = x.view(2,-1)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "transpose() vs permute() \n",
    "\n",
    "transpose() : 정확하게 두 개의 차원만을 맞교환\n",
    "\n",
    "permute() : 모든 차원을 맞교환"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 16, 3])\n",
      "torch.Size([3, 16, 32])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(16,32,3)\n",
    "\n",
    "transposed1 = x.transpose(1,0) #첫번째와 두번째를 바꾼다. \n",
    "print(transposed1.shape)\n",
    "\n",
    "transposed2 = x.permute(2,0,1) #첫번째 인자가 두번째로 가고, 첫번쨰 인자가 맨 마지막으로\n",
    "print(transposed2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### view() permute() transpose()의 차이점"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permute()와 transpose()는 view()와 마찬가지로 tensor의 모양을 바꾸는데 사용가능 합니다. \n",
    "\n",
    "view() : 순서를 유지하되, 다음 차원으로 넘김\n",
    "\n",
    "permute() : transpose연산이 진행된다. -> permute가 transpose보다 상위 연산이라고 봐도 무방한가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = [\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4],\n",
    "    [1,2,3,4]\n",
    "]\n",
    "\n",
    "a = torch.Tensor(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original a : tensor([[1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.],\n",
      "        [1., 2., 3., 4.]])\n",
      "original viewed : tensor([[1., 2., 3.],\n",
      "        [4., 1., 2.],\n",
      "        [3., 4., 1.],\n",
      "        [2., 3., 4.]])\n",
      "viewed shape : torch.Size([4, 3])\n",
      "permuted shape : torch.Size([4, 3])\n"
     ]
    }
   ],
   "source": [
    "viewed = a.view(4,3)\n",
    "\n",
    "permuted = a.permute(1,0) #0을 1로보내고, 1을 0으로 보내기 -> transpose \n",
    "print('original a :',a)\n",
    "print('original viewed :',viewed)\n",
    "print('viewed shape :',viewed.shape)\n",
    "print('permuted shape :',permuted.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permute(), transpose(), view()의 또 한가지 차이점 \n",
    "\n",
    "view()는 오직 contiguous tensor에서만 작동할 수 있다. 그리고 반환하는 tensor역시 contiguous하다. \n",
    "\n",
    "transpose() : contiguous, non-contiguous 모두 작동할 수 있다. 그런데 view()와는 다르게 반환되는 tensor는 더 이상 contiguous하지 않다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### contigous하고 싶으면 transpose().contiguous()를 꼭 불러줘야 한다는 뜻!!!! permute()도 마찬가지"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "view() vs reshape()는 연산 자체는 같고, 기존 tensor가 변경되냐 되지 않느냐의 차이 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contiguous()의 의미\n",
    "\n",
    "tensor에서 바로 옆에 있는 요소가 실제로 메모리 상에서 서로 인접해있느냐를 의미"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2688545326720\n",
      "2688545326720\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6]\n",
    "])\n",
    "y = x.transpose(1,0) #y는 contiguous하지 않다. \n",
    "\n",
    "\n",
    "#tensor x와 y는 동일한 memory space를 공유한다!!\n",
    "print(x.data_ptr())\n",
    "print(y.data_ptr())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x는 contigous한 view생성 객체이므로 x[0][0]과 x[0][1]은 memory에서 이웃하지만,\n",
    "y[0][1]과 y[0][0]은 이웃하지 않다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(x.is_contiguous())\n",
    "print(y.is_contiguous())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permute()를 사용할 때에는 permute(1,0,2).contiguous() 이런 식으로 붙여서, continuity를 유지할 수 있도록 하자. \n",
    "\n",
    "view() 붙어 있는 차원을 떼어낼 때 쓰자!! [B*2,C,D] -> [B,2,C,D]\n",
    "\n",
    "1인 차원 생성/제거할 때는 unsqueeze, squeeze함수를 쓰자. \n",
    "\n",
    "참고로 squeeze()를 쓸 때에는 없애려는 차원을 꼭 지정하자. 안그려면 batch=1일 때 batch가 날라가서 오류날 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test1 shape : torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "test1 = torch.rand(3,4,5)\n",
    "print(\"test1 shape :\",test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueezed1.shape : torch.Size([3, 1, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "unsqueezed1 = test1.unsqueeze(1) #size가 1인 차원을 생성합니다. \n",
    "print(\"unsqueezed1.shape :\",unsqueezed1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([3, 1, 4, 5])\n",
      "squeezed1 shape  torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "print(test1.shape)\n",
    "print(unsqueezed1.shape)\n",
    "squeezed1 = test1.squeeze(1) #첫 번째 차원을 제거합니다.\n",
    "print('squeezed1 shape ',squeezed1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unsqueezed2 shpae : torch.Size([5, 2, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "test2 = torch.rand(1,5,2,4,1)\n",
    "unsqueezed2 = test2.squeeze(0) #차원이 1인 부분을 삭제합니다. \n",
    "print('unsqueezed2 shpae :',unsqueezed2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test2.shape : torch.Size([1, 5, 2, 4, 1])\n",
      "unsqueezed3 shape  torch.Size([1, 5, 2, 4])\n"
     ]
    }
   ],
   "source": [
    "print('test2.shape :',test2.shape)\n",
    "unsqueezed3 = test2.squeeze(4)\n",
    "print(\"unsqueezed3 shape \",unsqueezed3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1c45c269bc2f1467f51b0d7ce18bdfa2841a09c768d41ed69b0f11077738bf91"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
