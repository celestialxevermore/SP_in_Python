{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "클래스 + 파이토치로 모델 구현하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F \n",
    "import torch.optim as optim \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(model,self).__init__()\n",
    "        #self.x_train = x_train \n",
    "\n",
    "        self.layer1 = nn.Linear(5,5)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.layer2 = nn.Linear(5,3)\n",
    "        \n",
    "        self.layer3 = nn.Linear(3,1)\n",
    "        \n",
    "    def forward(self,x_train):\n",
    "        x1 = self.layer1(x_train)\n",
    "        x2 = self.relu(x1)\n",
    "\n",
    "        x3 = self.layer2(x2)\n",
    "        x4 = self.relu(x3)\n",
    "        x5 = self.layer3(x4)\n",
    "        x6= self.relu(x5)\n",
    "        #x6 = nn.ReLU(x5)\n",
    "        return x6\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = torch.FloatTensor([ \n",
    "    [24,13,24,13,45],\n",
    "    [15,76,25,64,24],\n",
    "    [64,134,55,13,66],\n",
    "    [13,14,66,23,75], \n",
    "    [77,13,55,23,87]\n",
    "])\n",
    "\n",
    "y_train = torch.FloatTensor([\n",
    "    [13],\n",
    "    [24],\n",
    "    [55],\n",
    "    [45],\n",
    "    [11]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel = model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(mymodel.parameters(),lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/10000 Cost: 1183.199951\n",
      "Epoch  100/10000 Cost: 1183.199951\n",
      "Epoch  200/10000 Cost: 1183.199951\n",
      "Epoch  300/10000 Cost: 1183.199951\n",
      "Epoch  400/10000 Cost: 1183.199951\n",
      "Epoch  500/10000 Cost: 1183.199951\n",
      "Epoch  600/10000 Cost: 1183.199951\n",
      "Epoch  700/10000 Cost: 1183.199951\n",
      "Epoch  800/10000 Cost: 1183.199951\n",
      "Epoch  900/10000 Cost: 1183.199951\n",
      "Epoch 1000/10000 Cost: 1183.199951\n",
      "Epoch 1100/10000 Cost: 1183.199951\n",
      "Epoch 1200/10000 Cost: 1183.199951\n",
      "Epoch 1300/10000 Cost: 1183.199951\n",
      "Epoch 1400/10000 Cost: 1183.199951\n",
      "Epoch 1500/10000 Cost: 1183.199951\n",
      "Epoch 1600/10000 Cost: 1183.199951\n",
      "Epoch 1700/10000 Cost: 1183.199951\n",
      "Epoch 1800/10000 Cost: 1183.199951\n",
      "Epoch 1900/10000 Cost: 1183.199951\n",
      "Epoch 2000/10000 Cost: 1183.199951\n",
      "Epoch 2100/10000 Cost: 1183.199951\n",
      "Epoch 2200/10000 Cost: 1183.199951\n",
      "Epoch 2300/10000 Cost: 1183.199951\n",
      "Epoch 2400/10000 Cost: 1183.199951\n",
      "Epoch 2500/10000 Cost: 1183.199951\n",
      "Epoch 2600/10000 Cost: 1183.199951\n",
      "Epoch 2700/10000 Cost: 1183.199951\n",
      "Epoch 2800/10000 Cost: 1183.199951\n",
      "Epoch 2900/10000 Cost: 1183.199951\n",
      "Epoch 3000/10000 Cost: 1183.199951\n",
      "Epoch 3100/10000 Cost: 1183.199951\n",
      "Epoch 3200/10000 Cost: 1183.199951\n",
      "Epoch 3300/10000 Cost: 1183.199951\n",
      "Epoch 3400/10000 Cost: 1183.199951\n",
      "Epoch 3500/10000 Cost: 1183.199951\n",
      "Epoch 3600/10000 Cost: 1183.199951\n",
      "Epoch 3700/10000 Cost: 1183.199951\n",
      "Epoch 3800/10000 Cost: 1183.199951\n",
      "Epoch 3900/10000 Cost: 1183.199951\n",
      "Epoch 4000/10000 Cost: 1183.199951\n",
      "Epoch 4100/10000 Cost: 1183.199951\n",
      "Epoch 4200/10000 Cost: 1183.199951\n",
      "Epoch 4300/10000 Cost: 1183.199951\n",
      "Epoch 4400/10000 Cost: 1183.199951\n",
      "Epoch 4500/10000 Cost: 1183.199951\n",
      "Epoch 4600/10000 Cost: 1183.199951\n",
      "Epoch 4700/10000 Cost: 1183.199951\n",
      "Epoch 4800/10000 Cost: 1183.199951\n",
      "Epoch 4900/10000 Cost: 1183.199951\n",
      "Epoch 5000/10000 Cost: 1183.199951\n",
      "Epoch 5100/10000 Cost: 1183.199951\n",
      "Epoch 5200/10000 Cost: 1183.199951\n",
      "Epoch 5300/10000 Cost: 1183.199951\n",
      "Epoch 5400/10000 Cost: 1183.199951\n",
      "Epoch 5500/10000 Cost: 1183.199951\n",
      "Epoch 5600/10000 Cost: 1183.199951\n",
      "Epoch 5700/10000 Cost: 1183.199951\n",
      "Epoch 5800/10000 Cost: 1183.199951\n",
      "Epoch 5900/10000 Cost: 1183.199951\n",
      "Epoch 6000/10000 Cost: 1183.199951\n",
      "Epoch 6100/10000 Cost: 1183.199951\n",
      "Epoch 6200/10000 Cost: 1183.199951\n",
      "Epoch 6300/10000 Cost: 1183.199951\n",
      "Epoch 6400/10000 Cost: 1183.199951\n",
      "Epoch 6500/10000 Cost: 1183.199951\n",
      "Epoch 6600/10000 Cost: 1183.199951\n",
      "Epoch 6700/10000 Cost: 1183.199951\n",
      "Epoch 6800/10000 Cost: 1183.199951\n",
      "Epoch 6900/10000 Cost: 1183.199951\n",
      "Epoch 7000/10000 Cost: 1183.199951\n",
      "Epoch 7100/10000 Cost: 1183.199951\n",
      "Epoch 7200/10000 Cost: 1183.199951\n",
      "Epoch 7300/10000 Cost: 1183.199951\n",
      "Epoch 7400/10000 Cost: 1183.199951\n",
      "Epoch 7500/10000 Cost: 1183.199951\n",
      "Epoch 7600/10000 Cost: 1183.199951\n",
      "Epoch 7700/10000 Cost: 1183.199951\n",
      "Epoch 7800/10000 Cost: 1183.199951\n",
      "Epoch 7900/10000 Cost: 1183.199951\n",
      "Epoch 8000/10000 Cost: 1183.199951\n",
      "Epoch 8100/10000 Cost: 1183.199951\n",
      "Epoch 8200/10000 Cost: 1183.199951\n",
      "Epoch 8300/10000 Cost: 1183.199951\n",
      "Epoch 8400/10000 Cost: 1183.199951\n",
      "Epoch 8500/10000 Cost: 1183.199951\n",
      "Epoch 8600/10000 Cost: 1183.199951\n",
      "Epoch 8700/10000 Cost: 1183.199951\n",
      "Epoch 8800/10000 Cost: 1183.199951\n",
      "Epoch 8900/10000 Cost: 1183.199951\n",
      "Epoch 9000/10000 Cost: 1183.199951\n",
      "Epoch 9100/10000 Cost: 1183.199951\n",
      "Epoch 9200/10000 Cost: 1183.199951\n",
      "Epoch 9300/10000 Cost: 1183.199951\n",
      "Epoch 9400/10000 Cost: 1183.199951\n",
      "Epoch 9500/10000 Cost: 1183.199951\n",
      "Epoch 9600/10000 Cost: 1183.199951\n",
      "Epoch 9700/10000 Cost: 1183.199951\n",
      "Epoch 9800/10000 Cost: 1183.199951\n",
      "Epoch 9900/10000 Cost: 1183.199951\n",
      "Epoch 10000/10000 Cost: 1183.199951\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs+1):\n",
    "\n",
    "    #가설\n",
    "    prediction = mymodel.forward(x_train)\n",
    "\n",
    "\n",
    "    cost  = torch.nn.functional.mse_loss(prediction,y_train)\n",
    "\n",
    "    cost.backward() \n",
    "    optimizer.step() \n",
    "\n",
    "    if epoch % 100 == 0:\n",
    "    # 100번마다 로그 출력\n",
    "      print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "          epoch, epochs, cost.item()\n",
    "      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "168ed19636e745bfbe4a91e9a649e49a89eb5d69331d40be8dade616bde7bd16"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('pytorchproject': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
